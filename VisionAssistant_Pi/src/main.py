"""
main.py ‚Äî Vision Caption + Piper Speech Module (fixed capture logic)
Author: Geo & ChatGPT (2025)
"""

import cv2
import time
import subprocess
from pathlib import Path
from vision_caption.blip_model import load_blip
from vision_caption.captioner import generate_caption
from vision_caption.speak_piper import speak_piper



# ------------------------------------------------------------
# üîä Piper Text-to-Speech Helper
# ------------------------------------------------------------
def speak_piper(text: str, model_path="~/piper_voices/en_US-amy-medium.onnx"):
    """Speak text using Piper neural TTS."""
    model_path = str(Path(model_path).expanduser())
    try:
        p1 = subprocess.Popen(
            ["piper", "--model", model_path, "--output_audio", "pipe"],
            stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL
        )
        p2 = subprocess.Popen(["aplay"], stdin=p1.stdout,
                              stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        p1.stdin.write(text.encode("utf-8"))
        p1.stdin.close()
        p1.wait()
        p2.wait()
    except Exception as e:
        print(f"‚ö†Ô∏è Piper TTS error: {e}")


# ------------------------------------------------------------
# üé• Capture + Caption Loop
# ------------------------------------------------------------
def main():
    print("üöÄ Initializing Vision Caption + Piper TTS module...")

    model, processor = load_blip()
    print("‚úÖ BLIP model loaded and ready.\nPress Enter to capture or 'q' to quit.\n")

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå Could not access camera.")
        return

    try:
        while True:
            key = input("Press Enter to capture, or 'q' to quit: ")
            if key.lower() == "q":
                print("üëã Exiting Vision Caption module.")
                break

            # Flush camera buffer (grab a few frames before capture)
            for _ in range(4):
                cap.grab()
            time.sleep(0.3)  # allow camera to update

            ret, frame = cap.read()
            if not ret:
                print("‚ùå Failed to capture image.")
                continue

            image_path = Path("webcam.jpg")
            cv2.imwrite(str(image_path), frame)
            print("üì∏ Image captured ‚Üí webcam.jpg")

            # Generate caption
            t0 = time.time()
            caption = generate_caption(model, processor, str(image_path))
            print(f"üß† Caption: {caption}")
            print(f"‚è±Ô∏è Inference Time: {time.time() - t0:.2f} s")

            from vision_caption.speak_piper import speak_piper
            speak_piper(caption)


    except KeyboardInterrupt:
        print("\nüõë Interrupted by user.")
    finally:
        cap.release()
        print("‚úÖ Camera released. Goodbye.")


if __name__ == "__main__":
    main()
